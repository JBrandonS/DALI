{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.3.5\n",
      "numpy version: 1.20.3\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parth import *\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "import concurrent.futures\n",
    "\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'numpy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some input values (i.e. DNNU) modify a diffrent output parameter (N_nu)\n",
    "parth_inout_map = {\n",
    "    'DNNU': 'N_nu',\n",
    "    'ETA10': 'eta10',\n",
    "    'TAU': 'tau'\n",
    "}\n",
    "\n",
    "# !!! will need to update card_mod if you change obs\n",
    "# k, v of intrested obs: expermental errors \n",
    "observables = {\n",
    "    'H2/H': 0.03* 10**(-5),     # https://arxiv.org/abs/1710.11129       \n",
    "    'Y_p': 0.0026,     # https://arxiv.org/abs/1904.01594 8 26 22\n",
    "    'tau': 0.5          #pdg       \n",
    "}\n",
    "\n",
    "# See https://arxiv.org/pdf/0705.0290.pdf Table I\n",
    "# Modifcations to the base card to always be considered\n",
    "card_mod = {\n",
    "    'OUTPUT': 'F  2  3 6'\n",
    "}\n",
    "\n",
    "# params to vary over and step size, uses parth's card syntax\n",
    "parameters = {\n",
    "    'ETA10': 0.005,\n",
    "    'DNNU': 0.036, \n",
    "    'TAU': 0.5\n",
    "}\n",
    "\n",
    "# cleans up output\n",
    "obs_and_params = list(observables.keys()) + [parth_inout_map.get(k, k) for k in parameters.keys()]\n",
    "\n",
    "# otherwise we will just find fisher\n",
    "use_dali = True\n",
    "\n",
    "save = True\n",
    "save_file = 'bbn__small_t' + str(observables['tau']) + '.pkl'\n",
    "\n",
    "# these are to match lesnpower output so we can just use the cobaya dali program\n",
    "lo_spec_id = 'unlensed'\n",
    "lo_experment = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp(val):\n",
    "    display(val)\n",
    "\n",
    "def _run(param, mod):\n",
    "    nope = Pyrthenope(card_mod=mod)\n",
    "    for (k, v) in param:\n",
    "        nope.card[k] = nope.card[k] + v\n",
    "    return nope.run()    \n",
    "\n",
    "def runner(obs, params, cardMods=None, doDali=True, numThreads=cpu_count()):\n",
    "    # This generates all of our runs, these will run automagically and will only halt when a corresponding .result() is called\n",
    "    processes = np.empty((2**doDali, len(params), len(params), 2**(1+doDali)), dtype=object)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=numThreads) as exec:\n",
    "        for i, (param1, step1) in enumerate(params.items()):\n",
    "            processes[0, i, 0, 0] = exec.submit(_run, [(param1, -step1/2)], cardMods)\n",
    "            processes[0, i, 0, 1] = exec.submit(_run, [(param1,  step1/2)], cardMods)\n",
    "            if doDali:\n",
    "                for j, (param2, step2) in enumerate(params.items()):\n",
    "                    processes[1, i, j, 0] = exec.submit(_run, [(param1, -step1/2), (param2, -step2/2)], cardMods)\n",
    "                    processes[1, i, j, 1] = exec.submit(_run, [(param1,  step1/2), (param2, -step2/2)], cardMods)\n",
    "                    processes[1, i, j, 2] = exec.submit(_run, [(param1, -step1/2), (param2,  step2/2)], cardMods)\n",
    "                    processes[1, i, j, 3] = exec.submit(_run, [(param1,  step1/2), (param2,  step2/2)], cardMods)\n",
    "\n",
    "    # derivative vectors\n",
    "    d1Vec = pd.DataFrame()\n",
    "    d2Vec = pd.DataFrame()\n",
    "\n",
    "    #calculate the derivatives\n",
    "    for i, (param1, step1) in enumerate(params.items()):\n",
    "        v01 = processes[0, i, 0, 0].result()\n",
    "        v02 = processes[0, i, 0, 1].result()\n",
    "        \n",
    "        d1 = pd.DataFrame((v02[obs] - v01[obs]) / step1).rename(index={0:param1})    \n",
    "        d1Vec = pd.concat([d1Vec, d1])\n",
    "\n",
    "        if doDali:\n",
    "            for j, (param2, step2) in enumerate(params.items()):\n",
    "                v11 = processes[1, i, j, 0].result()\n",
    "                v12 = processes[1, i, j, 1].result()\n",
    "                v13 = processes[1, i, j, 2].result()\n",
    "                v14 = processes[1, i, j, 3].result()\n",
    "\n",
    "                d11 = (v12[obs] - v11[obs]) / step1\n",
    "                d12 = (v14[obs] - v13[obs]) / step1\n",
    "                d2 = pd.DataFrame((d12 - d11) / step2).rename(index={0:(param1, param2)})\n",
    "                d2Vec = pd.concat([d2Vec, d2])\n",
    "\n",
    "    # Finds the (gaussian) 1/sigma^2 errors\n",
    "    errors = np.array([list(obs.values())])\n",
    "    isigma2 = pd.DataFrame(\n",
    "        np.linalg.inv(errors.T * np.identity(len(list(obs))) * errors), \n",
    "        index=[list(obs.keys())], columns=[list(obs.keys())])\n",
    "\n",
    "    # calculate fisher, dali3 and dali4\n",
    "    # https://arxiv.org/pdf/1401.6892.pdf 15\n",
    "    fisher = np.einsum('ia,ab,jb', d1Vec, isigma2, d1Vec)\n",
    "    if doDali:\n",
    "        # generate tensors so we can use these in np.einsum\n",
    "        d2Ten = d2Vec.values.reshape(len(params), len(params), len(obs))\n",
    "\n",
    "        dali3 = np.einsum('ija,ab,kb', d2Ten, isigma2, d1Vec)\n",
    "        dali4 = np.einsum('ija,ab,klb', d2Ten, isigma2, d2Ten)\n",
    "\n",
    "        return fisher, dali3, dali4, isigma2\n",
    "\n",
    "    return fisher, None, None, isigma2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseData = _run([], card_mod)\n",
    "# dp(baseData)\n",
    "\n",
    "fisher, dali3, dali4, is2 = runner(observables, parameters, card_mod, doDali=use_dali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    fid_values = {\n",
    "        'omega_b_h2': baseData['OmegaBh^2'].values[0], #0.02242 # check that this corresponds to our fid eta10 6.13332, is this needed?\n",
    "        'N_nu': baseData['N_nu'].values[0], #3.0,\n",
    "        'tau': baseData['tau'].values[0]\n",
    "    }\n",
    "    saveData = {'cosmoFid': fid_values, 'fisherGaussian': {lo_experment: {lo_spec_id: fisher}}, 'iSigma2': is2}\n",
    "    if use_dali:\n",
    "        saveData['DALI3Gaussian'] =  {lo_experment: {lo_spec_id: dali3}}\n",
    "        saveData['DALI4Gaussian'] =  {lo_experment: {lo_spec_id: dali4}}\n",
    "\n",
    "    with open(save_file, 'wb') as file:\n",
    "        pickle.dump(saveData, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('cmb-s4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "7690a1a30c5580e20242c57122f55054a6ee3577c9eff0e7721e071b8ee863a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
